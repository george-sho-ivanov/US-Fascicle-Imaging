{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb8dbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code segment from \n",
    "#https://github.com/njcronin/DL_Track/blob/master/Inference_Single_Image.ipynb\n",
    "#Neil J. Cronin, Taija Finni, Olivier Seynnes 10/Sep/2020\n",
    "\n",
    "from __future__ import division \n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import skeletonize\n",
    "from scipy.signal import resample, savgol_filter, butter, filtfilt\n",
    "from PIL import Image, ImageDraw\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "# Intersection over union (IoU), a measure of labelling accuracy (sometimes also called Jaccard score)\n",
    "def IoU(y_true, y_pred, smooth=1):\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
    "    union = K.sum(y_true,-1) + K.sum(y_pred,-1) - intersection\n",
    "    iou = (intersection + smooth) / ( union + smooth)\n",
    "    return iou\n",
    "\n",
    "# Function to sort contours from proximal to distal (the bounding boxes are not used)\n",
    "def sort_contours(cnts):\n",
    "    # initialize the reverse flag and sort index\n",
    "    i = 1\n",
    "    # construct the list of bounding boxes and sort them from top to bottom\n",
    "    boundingBoxes = [cv2.boundingRect(c) for c in cnts]\n",
    "    (cnts, boundingBoxes) = zip(*sorted(zip(cnts, boundingBoxes), key=lambda b:b[1][i], reverse=False))\n",
    " \n",
    "    return (cnts, boundingBoxes)\n",
    "\n",
    "# Find only the coordinates representing one edge of a contour. edge: T (top) or B (bottom)\n",
    "def contour_edge(edge, contour):\n",
    "    pts = list(contour)\n",
    "    ptsT = sorted(pts, key=lambda k: [k[0][0], k[0][1]])\n",
    "    allx = []\n",
    "    ally = []\n",
    "    for a in range(0,len(ptsT)):\n",
    "        allx.append(ptsT[a][0,0])\n",
    "        ally.append(ptsT[a][0,1])\n",
    "    un = np.unique(allx)\n",
    "    #sumA = 0\n",
    "    leng = len(un)-1\n",
    "    x = []\n",
    "    y = []\n",
    "    for each in range(5,leng-5): # Ignore 1st and last 5 points to avoid any curves\n",
    "        indices = [i for i, x in enumerate(allx) if x == un[each]]\n",
    "        if edge == 'T':\n",
    "            loc = indices[0]\n",
    "        else:\n",
    "            loc = indices[-1]\n",
    "        x.append(ptsT[loc][0,0])\n",
    "        y.append(ptsT[loc][0,1])\n",
    "    return np.array(x),np.array(y)\n",
    "\n",
    "def intersection(L1, L2):\n",
    "    D  = L1[0] * L2[1] - L1[1] * L2[0]\n",
    "    Dx = L1[2] * L2[1] - L1[1] * L2[2]\n",
    "    Dy = L1[0] * L2[2] - L1[2] * L2[0]\n",
    "    if D != 0:\n",
    "        x = Dx / D\n",
    "        y = Dy / D\n",
    "        return x,y\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# Function to detect mouse clicks for the purpose of image calibration\n",
    "def mclick(event, x, y, flags, param):\n",
    "    # grab references to the global variables\n",
    "    global mlocs\n",
    "\n",
    "    # if the left mouse button was clicked, record the (x, y) coordinates\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        mlocs.append(y)\n",
    "        \n",
    "# Function to compute the distance between 2 x,y points\n",
    "def distFunc(x1, y1, x2, y2):\n",
    "    xdist = (x2 - x1)**2\n",
    "    ydist = (y2 - y1)**2\n",
    "    return np.sqrt(xdist + ydist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abc3117",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#environment requirements available from: https://github.com/njcronin/DL_Track/blob/master/requirements.txt\n",
    "!pip install tf2onnx\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e226746",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load DL-Track's U-net model as a Tensorflow model and convert to an onnx model with onnx python API\n",
    "import tf2onnx\n",
    "\n",
    "old_apo_model = tf.keras.models.load_model('./models/model-apo-nc.h5', custom_objects={'IoU': IoU})\n",
    "old_fasc_model = tf.keras.models.load_model('./models/model-fascSnippets2-nc.h5', custom_objects={'IoU': IoU})\n",
    "onnx_apo_model, _ = tf2onnx.convert.from_keras(old_apo_model)\n",
    "onnx_fasc_model, _ = tf2onnx.convert.from_keras(old_fasc_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426132da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save new ONNX model\n",
    "\n",
    "import onnx\n",
    "onnx.save(onnx_apo_model, \"./onnx_model/onnx_model_apo.onnx\")\n",
    "onnx.save(onnx_fasc_model, \"./onnx_model/onnx_model_fasc.onnx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
